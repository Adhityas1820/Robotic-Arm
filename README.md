# Robotic-Arm
# ğŸ¤– AI Robotic Arm

An AI-powered robotic arm that understands natural language and sees the world. Tell it what to do, and it figures out the rest.

> "Point at the scissors" â†’ Gemini sees the scissors â†’ Servo points at them

---

## ğŸ¥ Demo

*Coming soon*

---

## ğŸ¯ What It Does

You speak naturally. The robot understands.

| You Say | What Happens |
|---------|--------------|
| "Point at the water bottle" | Gemini locates it, servo points at it |
| "Turn on LED 1" | LED turns on |
| "Sweep left to right" | Servo scans the area |
| "Point at the red object" | Finds and points at red objects |

---

## ğŸ§  How It Works
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   You       â”‚â”€â”€â”€â”€â–¶â”‚   Gemini    â”‚â”€â”€â”€â”€â–¶â”‚  Arduino    â”‚
â”‚  (command)  â”‚     â”‚  (vision +  â”‚     â”‚  (servo +   â”‚
â”‚             â”‚     â”‚   brain)    â”‚     â”‚   LEDs)     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â”‚
                           â–¼
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚   OpenCV    â”‚
                    â”‚  (visual    â”‚
                    â”‚  feedback)  â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### The Visual Feedback Loop

This is the cool part. Instead of calculating exact angles mathematically, the system **watches itself** and self-corrects:

1. Gemini identifies target coordinates from the image
2. OpenCV tracks colored markers on the servo arm
3. System calculates error between "where it's pointing" and "where it should point"
4. Servo adjusts until aligned
5. Repeat until error < 2Â°

**This makes it accurate without precise calibration.**

---

## ğŸ› ï¸ Tech Stack

| Component | Purpose |
|-----------|---------|
| **Google Gemini API** | Vision + natural language understanding |
| **OpenCV** | Real-time marker tracking |
| **Python** | Core application |
| **Arduino** | Hardware control |
| **Servo Motor** | Physical pointing |

---

## ğŸ“¦ Hardware Setup
```
Camera (iPad via Camo)
       â”‚
       â–¼
 â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
 â”‚  Scene    â”‚ â† Objects to point at
 â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
    [Servo]
       â”‚
       â–¼
   Arduino
```

### Components
- Arduino Uno
- Servo motor (with colored markers for tracking)
- 3x LEDs
- Webcam or phone camera (I used iPad + Camo)

### Marker Setup
- **Green marker** on servo axis (pivot point)
- **Pink marker** on servo arm tip

---

## ğŸš€ Getting Started

### 1. Clone the repo
```bash
git clone https://github.com/YOUR_USERNAME/robotic-arm.git
cd robotic-arm
```

### 2. Install dependencies
```bash
pip install opencv-python numpy pyserial google-genai
```

### 3. Set up your API key
```bash
export GEMINI_API_KEY="your-api-key-here"
```

### 4. Upload Arduino code
Upload `arduino/servo_control.ino` to your Arduino.

### 5. Run it
```bash
python main.py
```

---

## ğŸ“ Project Structure
```
robotic-arm/
â”œâ”€â”€ main.py              # Main application
â”œâ”€â”€ calibration.py       # Calibration tool
â”œâ”€â”€ test_tracking.py     # Test marker detection
â”œâ”€â”€ arduino/
â”‚   â””â”€â”€ servo_control.ino
â”œâ”€â”€ calibration.json     # Saved calibration data
â””â”€â”€ README.md
```

---

## ğŸ® Commands

### Visual Commands (uses camera)
- `"Point at the [object]"`
- `"Find the [object]"`
- `"Where is the [object]?"`

### Blind Commands (no camera needed)
- `"Look left"` / `"Look right"`
- `"Go to 90 degrees"`
- `"Sweep back and forth"`

### LED Commands
- `"Turn on LED 1"`
- `"Turn off all LEDs"`
- `"Blink LED 2"`

---

## ğŸ“ Current Status

- âœ… Natural language control via Gemini
- âœ… Visual object detection
- âœ… Self-correcting visual feedback loop
- âœ… Real-time marker tracking
- âœ… LED control
- ğŸ”„ **In Progress:** Multi-joint arm
- ğŸ”„ **In Progress:** Gripper for picking up objects


---

## ğŸ”® Future Plans

1. **Add gripper** â€” Pick up and move objects
2. **More joints** â€” Full arm with shoulder, elbow, wrist
3. **Object tracking** â€” Follow moving objects
4. **Voice control** â€” Speak commands instead of typing

---

## ğŸ“ What I Learned

- Integrating LLMs with physical hardware
- Visual feedback loops for self-correcting systems
- HSV color space for reliable object tracking
- Serial communication between Python and Arduino
- Building end-to-end AI systems

---

## ğŸ¤ Contributing

This is a personal project, but feel free to fork it and build your own version!

---

## ğŸ“„ License

MIT License â€” do whatever you want with it.

---

### Built by Adhitya 

*Started as a late-night coding session. Ended up becoming a robot.*
